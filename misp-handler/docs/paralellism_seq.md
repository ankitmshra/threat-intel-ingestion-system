# Paralellism Sequence Diagram
```mermaid
sequenceDiagram
    participant Client as ðŸŽ¯ Client/Trigger
    participant Orch as ðŸŽ­ Orchestrator Lambda
    participant Config as ðŸ”§ Config (PS/SM)
    participant MISP as ðŸŒ MISP Server
    participant TE as ðŸ§µ ThreadPoolExecutor
    participant BP1 as âš™ï¸ Batch Processor 1
    participant BP2 as âš™ï¸ Batch Processor 2
    participant BPN as âš™ï¸ Batch Processor N
    participant RQ as ðŸ”„ Retry Queue
    participant CW as ðŸ“Š CloudWatch

    Note over Client,CW: ðŸš€ System Initialization & Configuration
    Client->>Orch: Trigger Processing
    Orch->>Config: Load Configuration
    Config-->>Orch: max-events-per-instance: 100<br/>max-concurrent-instances: 10
    
    Note over Orch,MISP: ðŸ“Š Event Count & Batch Calculation
    Orch->>MISP: get_events_count_since_last_sync()
    MISP-->>Orch: Total Events: 850
    
    Orch->>Orch: calculate_batch_distribution()<br/>850 events Ã· 100 per instance = 9 batches<br/>Min(9, 10 max instances) = 9 instances
    
    Note over Orch,BPN: âš¡ Parallel Lambda Invocation (Concurrent)
    Orch->>TE: Create ThreadPoolExecutor(max_workers=9)
    
    par Concurrent Lambda Invocations
        TE->>BP1: invoke_lambda_sync(page=1, batch_size=100)
    and
        TE->>BP2: invoke_lambda_sync(page=2, batch_size=100) 
    and
        TE->>BPN: invoke_lambda_sync(page=N, batch_size=100)
    end
    
    Note over BP1,MISP: ðŸ”„ Parallel Event Fetching (Each processor works independently)
    par Parallel Event Processing
        BP1->>MISP: get_events_batch(page=1, batch_size=100)
        MISP-->>BP1: Events 1-100
        BP1->>BP1: Process Events 1-100
        BP1->>CW: Log Processing Status
    and
        BP2->>MISP: get_events_batch(page=2, batch_size=100)
        MISP-->>BP2: Events 101-200
        BP2->>BP2: Process Events 101-200
        BP2->>CW: Log Processing Status
    and
        BPN->>MISP: get_events_batch(page=N, batch_size=100)
        MISP-->>BPN: Events (N-1)*100 to N*100
        BPN->>BPN: Process Events
        BPN->>CW: Log Processing Status
    end
    
    Note over BP1,RQ: âš ï¸ Failure Handling (If Any Job Fails)
    alt Job Success
        BP1-->>TE: âœ… JobResult(status="success", processed=100)
        BP2-->>TE: âœ… JobResult(status="success", processed=100)
        BPN-->>TE: âœ… JobResult(status="success", processed=100)
    else Job Failure  
        BP2-->>TE: âŒ JobResult(status="failed", error="Network timeout")
        TE->>RQ: Send failed job to retry queue
        RQ-->>TE: âœ… Queued for retry
    end
    
    Note over TE,Orch: ðŸ”„ Synchronous Wait & Result Aggregation
    TE->>TE: as_completed() - Wait for all jobs
    TE-->>Orch: All job results collected
    
    Orch->>Orch: evaluate_results()<br/>â€¢ Success: 8/9 (88.9%)<br/>â€¢ Failure: 1/9 (11.1%)<br/>â€¢ Status: "partial_success"
    
    Note over Orch,CW: ðŸ“‹ Final Reporting
    Orch->>CW: Log final orchestration results
    Orch-->>Client: {<br/>  "status": "partial_success",<br/>  "total_events_processed": 800,<br/>  "successful_jobs": 8,<br/>  "failed_jobs": 1,<br/>  "failure_rate": 0.111<br/>}
    
    Note over Client,CW: ðŸŽ¯ Key Parallelism Achievements
    Note right of CW: â€¢ 9 Lambda functions execute simultaneously<br/>â€¢ Each processes different page of events<br/>â€¢ ThreadPoolExecutor manages concurrency<br/>â€¢ Failed jobs don't block successful ones<br/>â€¢ Total time â‰ˆ max(individual_job_times)
```