# How paralellism is achieved
```mermaid
graph TB
    subgraph "ğŸ“Š Parallelism Strategy"
        subgraph "1ï¸âƒ£ Event Distribution"
            TC[ğŸ“ˆ Total Events Count<br/>Example: 850 events]
            CALC[ğŸ§® Batch Calculation<br/>850 / 100 = 8.5 = 9 batches<br/>Min 9, 10 max = 9 instances]
            TC --> CALC
        end
        
        subgraph "2ï¸âƒ£ Concurrent Execution"
            TPE[ğŸ§µ ThreadPoolExecutor<br/>max_workers = batch_count<br/>manages concurrent invocations]
            
            subgraph "Lambda Invocations (Parallel)"
                L1[âš™ï¸ Lambda 1<br/>Page 1: Events 1-100<br/>invoke_lambda_sync]
                L2[âš™ï¸ Lambda 2<br/>Page 2: Events 101-200<br/>invoke_lambda_sync]
                L3[âš™ï¸ Lambda 3<br/>Page 3: Events 201-300<br/>invoke_lambda_sync]
                LN[âš™ï¸ Lambda N<br/>Page N: Events N-1*100+1 to N*100<br/>invoke_lambda_sync]
            end
            
            TPE --> L1
            TPE --> L2
            TPE --> L3
            TPE --> LN
        end
        
        subgraph "3ï¸âƒ£ Independent Processing"
            subgraph "Each Lambda Independently"
                FETCH[ğŸ“¥ get_events_batch<br/>MISP API call with pagination]
                PROC[âš™ï¸ Process Events<br/>Business Logic]
                LOG[ğŸ“ CloudWatch Logging]
                
                FETCH --> PROC --> LOG
            end
        end
        
        subgraph "4ï¸âƒ£ Synchronization & Results"
            WAIT[â³ as_completed<br/>Wait for all jobs to finish<br/>No job blocks others]
            AGG[ğŸ“Š Aggregate Results<br/>Collect all JobResult objects]
            EVAL[âš–ï¸ evaluate_results<br/>Calculate success/failure rates]
            
            WAIT --> AGG --> EVAL
        end
    end
    
    subgraph "ğŸ—ï¸ Technical Architecture"
        subgraph "Orchestrator Lambda"
            OL[ğŸ­ LambdaOrchestrator<br/>Single entry point<br/>Calculates distribution<br/>Manages concurrent execution<br/>Waits for completion]
            
            subgraph "Key Components"
                MTFP[ğŸ”§ MispThreatFeedProcessor<br/>get_events_count_since_last_sync<br/>get_events_batch page batch_size]
                
                CONFIG[âš™ï¸ MispConfig<br/>max_events_per_instance<br/>max_concurrent_instances<br/>batch_processing_function_name]
                
                JOBS[ğŸ“‹ BatchJob Objects<br/>job_id, page, batch_size<br/>function_name, payload]
            end
            
            OL --> MTFP
            OL --> CONFIG
            OL --> JOBS
        end
        
        subgraph "Batch Processing Lambdas"
            subgraph "Instance 1"
                BP1[âš™ï¸ Batch Processor<br/>Processes Page 1]
                MISP1[ğŸŒ MISP API Call<br/>timestamp=24h, page=1, limit=100]
                BP1 --> MISP1
            end
            
            subgraph "Instance 2"
                BP2[âš™ï¸ Batch Processor<br/>Processes Page 2]
                MISP2[ğŸŒ MISP API Call<br/>timestamp=24h, page=2, limit=100]
                BP2 --> MISP2
            end
            
            subgraph "Instance N"
                BPN[âš™ï¸ Batch Processor<br/>Processes Page N]
                MISPN[ğŸŒ MISP API Call<br/>timestamp=24h, page=N, limit=100]
                BPN --> MISPN
            end
        end
    end
    
    subgraph "ğŸ’¡ Parallelism Benefits"
        subgraph "Performance Gains"
            SERIAL[ğŸ“ˆ Serial Processing<br/>Time = N Ã— T<br/>850 events Ã— 0.1s = 85s]
            PARALLEL[ğŸš€ Parallel Processing<br/>Time = Max T1, T2, TN<br/>= 100 events Ã— 0.1s = 10s<br/>8.5x speedup]
            
            SERIAL -.->|vs| PARALLEL
        end
        
        subgraph "Scalability Features"
            SCALE1[ğŸ“Š Auto-scaling<br/>Based on event count]
            SCALE2[âš¡ Configurable limits<br/>max_concurrent_instances]
            SCALE3[ğŸ”„ Failure isolation<br/>One failed job = total failure]
            SCALE4[ğŸ“ˆ Linear scaling<br/>More events = more instances]
        end
    end
    
    subgraph "ğŸ›¡ï¸ Error Handling & Resilience"
        subgraph "Failure Management"
            FH1[âš ï¸ Individual Job Failures<br/>Do not affect other jobs]
            FH2[ğŸ”„ Retry Queue<br/>Failed jobs queued for later]
            FH3[ğŸ“Š Threshold Monitoring<br/>20% warning, 50% halt]
            FH4[ğŸ“ Detailed Logging<br/>Per-job tracking and metrics]
        end
        
        subgraph "Recovery Mechanisms"
            REC1[ğŸ”„ Deferred Retry<br/>SQS queue for failed batches]
            REC2[âš–ï¸ Graceful Degradation<br/>Partial success handling]
            REC3[ğŸ“Š CloudWatch Monitoring<br/>Success/failure metrics]
        end
    end
    
    %% Styling
    classDef parallelStrategy fill:#e1f5fe,stroke:#01579b,stroke-width:2px,color:#000
    classDef techArch fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    classDef benefits fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px,color:#000
    classDef errorHandling fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    
    class TC,CALC,TPE,L1,L2,L3,LN,FETCH,PROC,LOG,WAIT,AGG,EVAL parallelStrategy
    class OL,MTFP,CONFIG,JOBS,BP1,BP2,BPN,MISP1,MISP2,MISPN techArch
    class SERIAL,PARALLEL,SCALE1,SCALE2,SCALE3,SCALE4 benefits
    class FH1,FH2,FH3,FH4,REC1,REC2,REC3 errorHandling
```